{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value = tf.constant(np.linspace(1,20,20))\n",
    "value = tf.expand_dims(value,-1)\n",
    "value = tf.expand_dims(value,0)\n",
    "#value = tf.expand_dims(value,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(20), Dimension(1)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_ex = tf.ones([3,1,1],tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(1), Dimension(1)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_ex.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 1)\n",
      "(3, 1, 1)\n",
      "3\n",
      "<type 'numpy.ndarray'>\n",
      "(1, 18, 1)\n",
      "[[[  3.]\n",
      "  [  6.]\n",
      "  [  9.]\n",
      "  [ 12.]\n",
      "  [ 15.]\n",
      "  [ 18.]\n",
      "  [ 21.]\n",
      "  [ 24.]\n",
      "  [ 27.]\n",
      "  [ 30.]\n",
      "  [ 33.]\n",
      "  [ 36.]\n",
      "  [ 39.]\n",
      "  [ 42.]\n",
      "  [ 45.]\n",
      "  [ 48.]\n",
      "  [ 51.]\n",
      "  [ 54.]]]\n",
      "(1, 20, 1)\n",
      "[[[  1.]\n",
      "  [  3.]\n",
      "  [  5.]\n",
      "  [  7.]\n",
      "  [  9.]\n",
      "  [ 11.]\n",
      "  [ 13.]\n",
      "  [ 15.]\n",
      "  [ 17.]\n",
      "  [ 19.]\n",
      "  [ 21.]\n",
      "  [ 23.]\n",
      "  [ 25.]\n",
      "  [ 27.]\n",
      "  [ 29.]\n",
      "  [ 31.]\n",
      "  [ 33.]\n",
      "  [ 35.]\n",
      "  [ 37.]\n",
      "  [ 39.]]]\n",
      "[[[  1.]\n",
      "  [  2.]\n",
      "  [  3.]\n",
      "  [  4.]\n",
      "  [  5.]\n",
      "  [  6.]\n",
      "  [  7.]\n",
      "  [  8.]\n",
      "  [  9.]\n",
      "  [ 10.]\n",
      "  [ 11.]\n",
      "  [ 12.]\n",
      "  [ 13.]\n",
      "  [ 14.]\n",
      "  [ 15.]\n",
      "  [ 16.]\n",
      "  [ 17.]\n",
      "  [ 18.]\n",
      "  [ 19.]\n",
      "  [ 20.]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "\n",
    "    def time_to_batch(value, dilation, name=None):\n",
    "        with tf.name_scope('time_to_batch'):\n",
    "            shape = tf.shape(value)\n",
    "            pad_elements = dilation - 1 - (shape[1] + dilation - 1) % dilation\n",
    "            padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]])\n",
    "            reshaped = tf.reshape(padded, [-1, dilation, shape[2]])\n",
    "            transposed = tf.transpose(reshaped, perm=[1, 0, 2])\n",
    "            return tf.reshape(transposed, [shape[0] * dilation, -1, shape[2]])\n",
    "\n",
    "\n",
    "    def batch_to_time(value, dilation, name=None):\n",
    "        with tf.name_scope('batch_to_time'):\n",
    "            shape = tf.shape(value)\n",
    "            prepared = tf.reshape(value, [dilation, -1, shape[2]])\n",
    "            transposed = tf.transpose(prepared, perm=[1, 0, 2])\n",
    "            return tf.reshape(transposed,\n",
    "                              [tf.div(shape[0], dilation), -1, shape[2]])\n",
    "\n",
    "\n",
    "    def causal_conv(value, filter_, dilation, name='causal_conv'):\n",
    "        with tf.name_scope(name):\n",
    "            filter_width = tf.shape(filter_)[0]\n",
    "            print value.get_shape()\n",
    "            print filter_.get_shape()\n",
    "            if dilation > 1:\n",
    "                transformed = time_to_batch(value, dilation)\n",
    "                print transformed.get_shape()\n",
    "                conv = tf.nn.conv1d(transformed, filter_, stride=1,\n",
    "                                    padding='VALID')\n",
    "                restored = batch_to_time(conv, dilation)\n",
    "            else:\n",
    "                restored = tf.nn.conv1d(value, filter_, stride=1, padding='SAME')\n",
    "            # Remove excess elements at the end.\n",
    "            out_width = tf.shape(value)[1] - (filter_width - 1) * dilation\n",
    "            result = tf.slice(restored,\n",
    "                              [0, 0, 0],\n",
    "                              [-1, out_width, -1])\n",
    "            return result\n",
    "        \n",
    "    def my_causal_conv(value, filter_, dilation, name='my_causal_conv'):\n",
    "        with tf.name_scope(name):\n",
    "            # assume dilation is 1\n",
    "            filter_width = filter_.get_shape().as_list()[0]\n",
    "            print filter_width\n",
    "            if filter_width%2 == 0:\n",
    "                mask_start = filter_width/2\n",
    "            else:\n",
    "                mask_start = filter_width/2 + 1\n",
    "            mask = np.ones(filter_.get_shape(),np.float32)\n",
    "            print type(mask)\n",
    "            mask[mask_start:filter_width,:,:] = 0\n",
    "            filter_ = tf.multiply(filter_,mask)\n",
    "            result = tf.nn.conv1d(value,filter_,stride=1,padding='SAME')\n",
    "            return result\n",
    "            \n",
    "        \n",
    "    value_ex = tf.constant(np.linspace(1,20,20),tf.float32)\n",
    "    value_ex = tf.expand_dims(value_ex,-1)\n",
    "    value_ex = tf.expand_dims(value_ex,0)\n",
    "    filter_ex = tf.ones([3,1,1],tf.float32)\n",
    "    \n",
    "    res = causal_conv(value_ex,filter_ex,1)\n",
    "    res2 = my_causal_conv(value_ex,filter_ex,1)\n",
    "    \n",
    "    result,result2,value_ex = session.run([res,res2,value_ex])\n",
    "    print result.shape\n",
    "    print result\n",
    "    print result2.shape\n",
    "    print result2\n",
    "    print value_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def causual_conv1d(value, filters, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def artrous_conv1d(value, filters, rate, padding, name=None):\n",
    "    '''\n",
    "    1d equivalent of the tensorflow artrous 2d convolution\n",
    "\n",
    "    Args:\n",
    "        value: input 3-D tensor with shape [batch_size, in_width, ip_channels]\n",
    "        filters: convolution filter with shape [filter_width, ip_channels, op_channels]\n",
    "        rate: rate of dilation, 1 is equivalent to normal convolution\n",
    "        padding: string, \"SAME\" or \"VALID\" only\n",
    "        name: function scoping name for tensorflow\n",
    "\n",
    "    Returns:\n",
    "    Tensor of shape [batch_size, new_width, op_channels]\n",
    "    '''\n",
    "    with tf.name_scope(name, \"artrous_conv1d\") as name:\n",
    "        if rate == 1:\n",
    "            # perform normal convolution\n",
    "            return tf.nn.conv1d(value,filters,stride=1,padding=padding)\n",
    "\n",
    "        elif rate > 1:\n",
    "            # determine padding based on padding choice\n",
    "            if padding == \"SAME\":\n",
    "                # based on the size of the kernel add zeroes to the image\n",
    "                filter_width = tf.shape(filters)[0]\n",
    "                overall_pad = filter_width + filter_width*(rate-1)\n",
    "                pad_left = overall_pad//2\n",
    "                pad_right = overall_pad - pad_left\n",
    "\n",
    "            else:\n",
    "                pad_left = 0\n",
    "                pad_right = 0\n",
    "\n",
    "            # check optimality with the rate provided\n",
    "            check_width = pad_left + tf.shape(value) + pad_right\n",
    "            pad_right_extra = (rate - check_width % rate) % rate\n",
    "            pad_right += pad_right_extra\n",
    "\n",
    "            # reshape value tensor based on type of padding and rate\n",
    "            new_value = space_to_batch_1d(value,[pad_left,pad_right],rate)\n",
    "\n",
    "            # perform 1d convolution\n",
    "            conv_new_value = tf.nn.conv1d(new_value,filters,stride=1,padding='VALID')\n",
    "\n",
    "            # re-shape the output to output size\n",
    "            conv_value = batch_to_space_1d(conv_new_value,[0,pad_right_extra],rate)\n",
    "\n",
    "            return conv_value\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Rate must be >= 1\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
